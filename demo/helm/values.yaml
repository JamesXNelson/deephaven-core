# Declare variables which will be passed into our templates (go templated yaml describing kubernetes resources).
#
# You can override any of these values on the command line when invoking helm.
# helm install --set someValue=whatever my-dh-install demo/helm
# https://helm.sh/docs/helm/helm_install/
#
# There is no specific format to this file or its values.
# These values will be referenced like {{ .Values.image.pullPolicy }} in our templates.
#
# We will separate "values managed by deephaven" from "values supplied by default helm chart


dh:

  # Top 2-lines are for local builds
#  version: local-build
#  repo: deephaven
  # Bottom 2-lines are for remote builds (see README.md for instructions on pushing images!)
  version: 0.0.4
  repo: us-central1-docker.pkg.dev/deephaven-oss/deephaven

  ipAddrName: dh-demo-ip
  #presharedCertName: dh-internal-key
  presharedCertName: dh-demo-us-central
  secretCertName: dh-demo-cert
  #secretCertName: dh-internal-key
  managedCertName: dh-auto-cert

  ingressName: dh-ingress
  portEnvoy: 10000
  portEnvoyInternal: 10000
  portGrpcApi: 8888
  portGrpcApiInternal: 8888
  #portGrpcApiInternal: 443
  portWeb: 8080
  portWebInternal: 8080
  # portWebInternal: 8443
  portControlInternal: 1771
  portControl: 7117
  envoyServiceType: NodePort
  serviceType: NodePort

  # Effectively, how long do we want user to be able to return to session.
  cookieTtlSeconds: 2700 # 45 minutes

  # If we want to allow long-lived connection, we need to allow a long backendResponseSeconds:
  # backendResponseSeconds: 2700 # 45 minutes
  # For a production system, you may want to allow more than 24 hrs.
  # hm... turning this way down, it seems to mess w/ health check somehow...
  backendResponseSeconds: 30

  svcNameGrpc: dh-grpc
  svcNameWeb: dh-web
  svcNameEnvoy: dh-envoy
  svcNameControl: dh-control
  #svcNameControl: dh-grpc
  frontendConfigName: dh-frontend
  dnsName: demo.deephavencommunity.com
  routeGrpc: dh-route-grpc
  routeWeb: dh-route-web

google:
  project: deephaven-oss
  region: us-central1
  svcAccountName: dhadmin@deephaven-oss.iam.gserviceaccount.com

envVars:
  - name: MY_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: MY_POD_NAME
    valueFrom:
      fieldRef:
        fieldPath: metadata.name
  - name: MY_POD_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
  - name: MY_POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP
  - name: HOST_IP
    valueFrom:
      fieldRef:
        fieldPath: status.hostIP
  - name: MY_POD_SERVICE_ACCOUNT
    valueFrom:
      fieldRef:
        fieldPath: spec.serviceAccountName


replicaCount: 1

image:
  pullPolicy: Always
#  pullPolicy: IfNotPresent

  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: "deephaven"
fullnameOverride: "dh-local"

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "deephaven"

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext:
  # capabilities:
  #   drop:
  #   - ALL
  privileged: false
  readOnlyRootFilesystem: false
  runAsNonRoot: false
  #runAsNonRoot: true
  # runAsUser: 1000

service:
  # NodePort is used to let us expose a port to the world outside our cluster
  type: NodePort
  port: 443

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  # targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 70

nodeSelector: {}

tolerations: []

affinity: {}

